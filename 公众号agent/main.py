"""
Deep Scholar AI - ä¸»åº”ç”¨å…¥å£ä¸åè°ƒå™¨

ä¸¥æ ¼éµå¾ªä¾èµ–æ³¨å…¥åŸåˆ™ï¼š
- ç³»ç»Ÿçš„å”¯ä¸€å…¥å£ç‚¹
- è´Ÿè´£è§£æå‘½ä»¤è¡Œå‚æ•°ã€åŠ è½½é…ç½®ã€åˆå§‹åŒ–æ‰€æœ‰æ ¸å¿ƒæœåŠ¡
- åè°ƒå„ä¸ªæ¨¡å—çš„å·¥ä½œæµï¼Œå®ç°å®Œæ•´çš„è®ºæ–‡å‘ç°åˆ°æ–‡ç« ç”Ÿæˆæµç¨‹
"""

import asyncio
import argparse
import sys
import signal
from pathlib import Path
from typing import Optional, List
import traceback

# å¯¼å…¥æ‰€æœ‰æ¨¡å—
from modules.config_manager import ConfigManager
from modules.logger import setup_logging, get_logger
from modules.llm_provider import LLMProviderService
from modules.embedding_provider import EmbeddingProviderService
from modules.memory_system import HybridMemorySystem
from modules.discovery_engine import DiscoveryEngine
from modules.ingestion_pipeline import IngestionPipeline
from modules.analysis_core import DeepAnalysisCore, AnalysisRequest
from modules.synthesis_engine import (
    SynthesisEngine,
    AnalysisPair as SynthesisAnalysisPair,
    GlobalAnalysisMap as SynthesisGlobalAnalysisMap,
    PaperMetadata as SynthesisPaperMetadata,
    FigureReference as SynthesisFigureReference,
)
from modules.learning_loop import LearningLoop


class DeepScholarAI:
    """
    Deep Scholar AI ä¸»åº”ç”¨ç±»
    
    åè°ƒæ‰€æœ‰æ¨¡å—çš„å·¥ä½œæµï¼Œå®ç°å®Œæ•´çš„è®ºæ–‡ç ”ç©¶åˆ°æ–‡ç« ç”Ÿæˆçš„æµç¨‹
    """
    
    def __init__(self):
        """æ— å‰¯ä½œç”¨æ„é€ å‡½æ•°"""
        self.logger = None
        self.config: Optional[ConfigManager] = None
        self.llm_provider: Optional[LLMProviderService] = None
        self.embedding_provider: Optional[EmbeddingProviderService] = None
        self.memory_system: Optional[HybridMemorySystem] = None
        self.discovery_engine: Optional[DiscoveryEngine] = None
        self.ingestion_pipeline: Optional[IngestionPipeline] = None
        self.analysis_core: Optional[DeepAnalysisCore] = None
        self.synthesis_engine: Optional[SynthesisEngine] = None
        self.learning_loop: Optional[LearningLoop] = None
        
        self._initialized = False
        self._shutdown_event = asyncio.Event()
        self._interactive_last_discovered = []  # [(paper_id, title)] for feedback mapping
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨
        self._setup_signal_handlers()
    
    def _setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨ä»¥ä¼˜é›…å…³é—­"""
        def signal_handler(signum, frame):
            print(f"\næ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
            try:
                loop = asyncio.get_running_loop()
                # åœ¨æ­£ç¡®çš„äº‹ä»¶å¾ªç¯çº¿ç¨‹ä¸Šè°ƒåº¦å…³é—­ä»»åŠ¡
                loop.call_soon_threadsafe(asyncio.create_task, self.shutdown())
            except RuntimeError:
                # é€€è·¯ï¼šæ— è¿è¡Œä¸­äº‹ä»¶å¾ªç¯æ—¶ï¼ŒåŒæ­¥åˆ›å»ºå¹¶è¿è¡Œä¸€ä¸ªä¸´æ—¶å¾ªç¯å…³é—­
                try:
                    asyncio.run(self.shutdown())
                except Exception:
                    pass
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
    
    async def initialize(self, config_path: str) -> None:
        """
        å¼‚æ­¥åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        try:
            print("æ­£åœ¨åˆå§‹åŒ– Deep Scholar AI...")
            
            # 1. åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
            self.config = ConfigManager()
            await self.config.initialize(config_path)
            print("âœ“ é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
            # 2. è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
            await setup_logging(self.config)
            self.logger = get_logger("deep_scholar_ai")
            self.logger.info("Deep Scholar AI å¼€å§‹åˆå§‹åŒ–")
            print("âœ“ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
            # 3. åˆå§‹åŒ–LLMæä¾›å•†æœåŠ¡
            self.llm_provider = LLMProviderService(self.config)
            self.logger.info("LLMæä¾›å•†æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            print("âœ“ LLMæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            
            # 4. åˆå§‹åŒ–åµŒå…¥æä¾›å•†æœåŠ¡
            self.embedding_provider = EmbeddingProviderService(self.config)
            self.logger.info("åµŒå…¥æä¾›å•†æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            print("âœ“ åµŒå…¥æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            
            # 5. åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
            self.memory_system = HybridMemorySystem(self.config, self.embedding_provider)
            await self.memory_system.initialize()
            self.logger.info("è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            print("âœ“ è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
            # 6. åˆå§‹åŒ–å‘ç°å¼•æ“
            self.discovery_engine = DiscoveryEngine(
                self.config,
                self.embedding_provider,
                self.llm_provider,
                self.memory_system,
            )
            await self.discovery_engine.initialize()
            self.logger.info("å‘ç°å¼•æ“åˆå§‹åŒ–å®Œæˆ")
            print("âœ“ å‘ç°å¼•æ“åˆå§‹åŒ–å®Œæˆ")
            
            # 7. åˆå§‹åŒ–æ¶ˆåŒ–ç®¡é“
            self.ingestion_pipeline = IngestionPipeline()
            await self.ingestion_pipeline.initialize(self.config)
            self.logger.info("æ¶ˆåŒ–ç®¡é“åˆå§‹åŒ–å®Œæˆ")
            print("âœ“ æ¶ˆåŒ–ç®¡é“åˆå§‹åŒ–å®Œæˆ")
            
            # 8. åˆå§‹åŒ–åˆ†ææ ¸å¿ƒ
            self.analysis_core = DeepAnalysisCore(
                self.config,
                self.llm_provider,
                self.memory_system,
                self.embedding_provider,
            )
            await self.analysis_core.initialize()
            self.logger.info("åˆ†ææ ¸å¿ƒåˆå§‹åŒ–å®Œæˆ")
            print("âœ“ åˆ†ææ ¸å¿ƒåˆå§‹åŒ–å®Œæˆ")
            
            # 9. åˆå§‹åŒ–åˆæˆå¼•æ“
            self.synthesis_engine = SynthesisEngine(self.config, self.llm_provider, self.memory_system)
            await self.synthesis_engine.initialize()
            self.logger.info("åˆæˆå¼•æ“åˆå§‹åŒ–å®Œæˆ")
            print("âœ“ åˆæˆå¼•æ“åˆå§‹åŒ–å®Œæˆ")

            # 10. åˆå§‹åŒ–å­¦ä¹ å¾ªç¯ï¼ˆæŒç»­è¿›åŒ–å›è·¯ï¼‰
            try:
                self.learning_loop = LearningLoop(
                    config=self.config,
                    memory_system=self.memory_system,
                    embedding_service=self.embedding_provider,
                )
                await self.learning_loop.initialize()
                # æ³¨å…¥åˆ° DiscoveryEngine ä¸ AnalysisCore
                try:
                    if self.discovery_engine:
                        self.discovery_engine.learning_loop = self.learning_loop
                        # è‹¥ TasteEngine å·²å¯ç”¨ï¼Œè¡¥å…¨æ³¨å…¥
                        if getattr(self.discovery_engine, "taste_engine", None):
                            self.learning_loop.set_taste_engine(self.discovery_engine.taste_engine)
                    if self.analysis_core:
                        self.analysis_core.learning_loop = self.learning_loop
                except Exception as _e:
                    self.logger.warning(f"LearningLoop cross-injection failed: {_e}")
            except Exception as e:
                self.logger.warning(f"LearningLoop åˆå§‹åŒ–å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰ï¼š{e}")
            
            self._initialized = True
            self.logger.info("Deep Scholar AI å…¨éƒ¨æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            print("ğŸš€ Deep Scholar AI åˆå§‹åŒ–å®Œæˆï¼Œç³»ç»Ÿå°±ç»ªï¼")
            
        except Exception as e:
            error_msg = f"åˆå§‹åŒ–å¤±è´¥: {e}"
            if self.logger:
                self.logger.error(error_msg, exc_info=True)
            else:
                print(f"âŒ {error_msg}")
                traceback.print_exc()
            raise
    
    async def run_discovery_cycle(self) -> None:
        """è¿è¡Œè®ºæ–‡å‘ç°å‘¨æœŸ"""
        if not self._initialized:
            raise RuntimeError("ç³»ç»Ÿæœªåˆå§‹åŒ–")
        
        self.logger.info("å¼€å§‹è®ºæ–‡å‘ç°å‘¨æœŸ")
        
        try:
            # å‘ç°æ–°è®ºæ–‡
            papers = await self.discovery_engine.discover_papers()
            self.logger.info(f"å‘ç° {len(papers)} ç¯‡è®ºæ–‡")
            
            if not papers:
                self.logger.info("æœªå‘ç°æ–°è®ºæ–‡ï¼Œè·³è¿‡æ­¤å‘¨æœŸ")
                return
            
            # æ ¹æ®å‘ç°å¼•æ“ç»“æœç­›é€‰ï¼ˆdiscover_papers å·²åŒ…å«è¯„åˆ†ä¸æ’åºæ—¶å¯çœç•¥å†æ¬¡æ’åºï¼‰
            # è‹¥éœ€é¢å¤–æ’åºï¼Œå¯å¯ç”¨ rank_papersï¼›æ­¤å¤„ä¸ºé¿å…é‡å¤è¯„åˆ†ï¼Œç›´æ¥åˆ‡ç‰‡
            top_papers = papers[: self.config.preferences.daily_paper_limit]
            
            self.logger.info(f"ç­›é€‰å‡º {len(top_papers)} ç¯‡é«˜è´¨é‡è®ºæ–‡")
            
            return top_papers
            
        except Exception as e:
            self.logger.error(f"è®ºæ–‡å‘ç°å‘¨æœŸå¤±è´¥: {e}", exc_info=True)
            raise
    
    async def process_paper(self, paper_url: str) -> Optional[str]:
        """
        å¤„ç†å•ç¯‡è®ºæ–‡ï¼Œä»ä¸‹è½½åˆ°æœ€ç»ˆæ–‡ç« ç”Ÿæˆ
        
        Args:
            paper_url: è®ºæ–‡URL
            
        Returns:
            ç”Ÿæˆçš„æ–‡ç« æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤„ç†å¤±è´¥åˆ™è¿”å›None
        """
        if not self._initialized:
            raise RuntimeError("ç³»ç»Ÿæœªåˆå§‹åŒ–")
        
        self.logger.info(f"å¼€å§‹å¤„ç†è®ºæ–‡: {paper_url}")
        
        try:
            # 1. ä¸‹è½½å’Œè§£æPDF
            self.logger.info("æ­¥éª¤ 1/4: ä¸‹è½½å’Œè§£æPDF")
            processed_paper = await self.ingestion_pipeline.process_paper(paper_url)
            
            if not processed_paper:
                self.logger.warning(f"è®ºæ–‡å¤„ç†å¤±è´¥: {paper_url}")
                return None
            
            self.logger.info(f"PDFè§£æå®Œæˆï¼Œæå– {len(processed_paper.sections)} ä¸ªç« èŠ‚")
            
            # 2. æ·±åº¦åˆ†æ
            self.logger.info("æ­¥éª¤ 2/4: æ·±åº¦åˆ†æè®ºæ–‡å†…å®¹")
            request = AnalysisRequest(
                paper_content=processed_paper.full_text,
                paper_title=processed_paper.metadata.title or "",
                paper_authors=processed_paper.metadata.authors or [],
                analysis_depth=3,
                include_mathematical_details=True,
                include_historical_context=True,
                custom_focus_areas=None,
                output_language="zh-CN",
            )
            analysis_result = await self.analysis_core.analyze_paper(request)

            self.logger.info(
                f"åˆ†æå®Œæˆï¼Œç”Ÿæˆ {len(analysis_result.chunk_explanations)} ä¸ªæ„ç¾¤è§£é‡Š"
            )
            
            # 3. å­˜å‚¨åˆ°è®°å¿†ç³»ç»Ÿ
            self.logger.info("æ­¥éª¤ 3/4: å­˜å‚¨åˆ°è®°å¿†ç³»ç»Ÿ")
            # å°†åˆ†æç»“æœå­˜å…¥æ··åˆè®°å¿†ç³»ç»Ÿï¼ˆçœŸå®å®ç°ï¼‰
            try:
                await self.memory_system.store_paper_analysis(
                    processed_paper.metadata,
                    analysis_result,
                )
            except Exception as e:
                self.logger.warning(f"store_paper_analysis failed: {e}")
            
            # 4. åˆæˆæ–‡ç« 
            self.logger.info("æ­¥éª¤ 4/4: åˆæˆæœ€ç»ˆæ–‡ç« ")

            # å°† DeepAnalysisCore çš„ç»“æœè½¬æ¢ä¸ºåˆæˆå¼•æ“çš„æ•°æ®ç»“æ„
            # 4.1 æ„å»ºåˆ†æå¯¹ï¼ˆoriginal=chunkå†…å®¹, analysis=è§£é‡Šï¼‰
            chunk_map = {c.chunk_id: c for c in analysis_result.semantic_chunks}
            analysis_pairs: List[SynthesisAnalysisPair] = []
            for exp in analysis_result.chunk_explanations:
                chunk = chunk_map.get(exp.chunk_id)
                if not chunk:
                    continue
                pair = SynthesisAnalysisPair(
                    original=chunk.content,
                    analysis=exp.explanation,
                    section_id=chunk.section_type,
                    confidence_score=exp.confidence_score,
                )
                analysis_pairs.append(pair)

            # 4.2 æ„å»ºå…¨å±€åˆ†ææ˜ å°„ï¼ˆè½¬æ¢ç»“æ„ï¼‰
            global_map_src = analysis_result.global_map
            significance = ", ".join(analysis_result.practical_implications[:5])
            s_global = SynthesisGlobalAnalysisMap(
                summary=analysis_result.overall_summary,
                key_insights=analysis_result.research_insights[:10],
                technical_terms=global_map_src.terminology_glossary,
                methodology_analysis=global_map_src.methodology_overview,
                significance_assessment=significance or ""
            )

            # 4.3 æ„å»ºè®ºæ–‡å…ƒæ•°æ®
            s_meta = SynthesisPaperMetadata(
                title=processed_paper.metadata.title,
                authors=processed_paper.metadata.authors,
                institutions=None,
                publication_date=(
                    processed_paper.metadata.publication_date.isoformat()
                    if processed_paper.metadata.publication_date
                    else None
                ),
                arxiv_id=processed_paper.metadata.arxiv_id,
                doi=processed_paper.metadata.doi,
                abstract=processed_paper.abstract,
            )

            # 4.4 å°†æ‘„å–é˜¶æ®µçš„å›¾ç‰‡æ˜ å°„ä¸ºåˆæˆå¼•æ“å›¾ç‰‡å¼•ç”¨ï¼Œå¹¶ç”Ÿæˆè¯­ä¹‰ä¸Šä¸‹æ–‡
            def _build_figure_context(page_number: int) -> str:
                try:
                    # ä¼˜å…ˆä½¿ç”¨åŒ…å«è¯¥é¡µçš„ç« èŠ‚æ ‡é¢˜ä¸å†…å®¹ç‰‡æ®µä½œä¸ºä¸Šä¸‹æ–‡
                    for sec in processed_paper.sections:
                        if sec and getattr(sec, 'page_numbers', None) and page_number in (sec.page_numbers or []):
                            title = (sec.title or '').strip()
                            excerpt = (sec.content or '')[:500].strip()
                            ctx_parts = [p for p in [title, excerpt] if p]
                            if ctx_parts:
                                return ' '.join(ctx_parts)
                    # å›é€€åˆ°æ‘˜è¦æˆ–å…¨æ–‡å‰ç¼€
                    if processed_paper.abstract:
                        return processed_paper.abstract[:500]
                    return processed_paper.full_text[:500]
                except Exception:
                    return processed_paper.abstract or processed_paper.full_text[:500]

            fig_refs: List[SynthesisFigureReference] = []
            try:
                for img in getattr(processed_paper, 'images', []) or []:
                    caption = (getattr(img, 'caption', None) or getattr(img, 'alt_text', None) or f"Figure (p.{getattr(img, 'page_number', '?')})").strip()
                    context = _build_figure_context(getattr(img, 'page_number', 0))
                    file_path = getattr(img, 'image_path', '') or ''
                    if file_path:
                        fig_refs.append(
                            SynthesisFigureReference(
                                figure_id=getattr(img, 'image_id', ''),
                                caption=caption,
                                file_path=file_path,
                                context=context,
                                relevance_score=0.0,
                            )
                        )
            except Exception as _e:
                self.logger.warning(f"æ„å»ºå›¾ç‰‡å¼•ç”¨å¤±è´¥ï¼Œå°†ç»§ç»­ä¸å¸¦å›¾ç‰‡: {_e}")

            article = await self.synthesis_engine.synthesize_article(
                analysis_pairs=analysis_pairs,
                global_analysis=s_global,
                paper_metadata=s_meta,
                figures=fig_refs,
            )
            self.logger.info(f"æ–‡ç« ç”Ÿæˆå®Œæˆ: {article.title}")
            
            # æ›´æ–°å“å‘³å¼•æ“ï¼ˆæ­£é¢åé¦ˆï¼‰
            await self.discovery_engine.update_taste_from_paper(
                processed_paper.metadata, positive=True
            )
            
            # è¿”å›ä¿å­˜è·¯å¾„
            return getattr(article, 'file_path', None)
            
        except Exception as e:
            self.logger.error(f"è®ºæ–‡å¤„ç†å¤±è´¥ {paper_url}: {e}", exc_info=True)
            
            # æ›´æ–°å“å‘³å¼•æ“ï¼ˆè´Ÿé¢åé¦ˆï¼‰
            try:
                if 'processed_paper' in locals():
                    await self.discovery_engine.update_taste_from_paper(
                        processed_paper.metadata, positive=False
                    )
            except:
                pass
            
            return None
    
    async def run_daily_workflow(self) -> None:
        """è¿è¡Œæ¯æ—¥å·¥ä½œæµ"""
        if not self._initialized:
            raise RuntimeError("ç³»ç»Ÿæœªåˆå§‹åŒ–")
        
        self.logger.info("å¼€å§‹æ¯æ—¥å·¥ä½œæµ")
        
        try:
            # 1. å‘ç°è®ºæ–‡
            top_papers = await self.run_discovery_cycle()
            
            if not top_papers:
                self.logger.info("ä»Šæ—¥æ— é«˜è´¨é‡è®ºæ–‡å‘ç°")
                return
            
            # 2. é€‰æ‹©æœ€å€¼å¾—æ·±åº¦è§£è¯»çš„è®ºæ–‡
            selected_paper = top_papers[0]  # é€‰æ‹©æ’åæœ€é«˜çš„è®ºæ–‡
            paper_title = getattr(selected_paper.metadata, 'title', None) or 'Unknown Paper'
            self.logger.info(f"é€‰æ‹©è®ºæ–‡è¿›è¡Œæ·±åº¦è§£è¯»: {paper_title}")
            
            # 3. å¤„ç†è®ºæ–‡
            paper_url = (
                getattr(selected_paper.metadata, 'pdf_url', None)
                or getattr(selected_paper.metadata, 'html_url', None)
                or getattr(selected_paper.metadata, 'source_url', None)
            )
            article_path = await self.process_paper(paper_url) if paper_url else None
            
            if article_path:
                self.logger.info(f"æ¯æ—¥å·¥ä½œæµå®Œæˆï¼Œæ–‡ç« å·²ç”Ÿæˆ: {article_path}")
                print(f"âœ… ä»Šæ—¥æ–‡ç« å·²ç”Ÿæˆ: {article_path}")
                # ç”Ÿæˆå­¦ä¹ è¿›åº¦æŠ¥å‘Šï¼ˆéé˜»å¡å¯å¿½ç•¥é”™è¯¯ï¼‰
                try:
                    if self.learning_loop:
                        await self.learning_loop.generate_progress_report()
                except Exception as _e:
                    self.logger.warning(f"ç”Ÿæˆå­¦ä¹ è¿›åº¦æŠ¥å‘Šå¤±è´¥: {_e}")
            else:
                self.logger.warning("æ¯æ—¥å·¥ä½œæµå®Œæˆï¼Œä½†æœªèƒ½ç”Ÿæˆæ–‡ç« ")
                print("âš ï¸ ä»Šæ—¥è®ºæ–‡å¤„ç†å¤±è´¥ï¼Œæœªèƒ½ç”Ÿæˆæ–‡ç« ")
            
        except Exception as e:
            self.logger.error(f"æ¯æ—¥å·¥ä½œæµå¤±è´¥: {e}", exc_info=True)
            print(f"âŒ æ¯æ—¥å·¥ä½œæµå¤±è´¥: {e}")
    
    async def run_interactive_mode(self) -> None:
        """è¿è¡Œäº¤äº’æ¨¡å¼"""
        if not self._initialized:
            raise RuntimeError("ç³»ç»Ÿæœªåˆå§‹åŒ–")
        
        self.logger.info("è¿›å…¥äº¤äº’æ¨¡å¼")
        print("\nğŸ“š Deep Scholar AI äº¤äº’æ¨¡å¼")
        print("å¯ç”¨å‘½ä»¤:")
        print("  1. discover - è¿è¡Œè®ºæ–‡å‘ç°")
        print("  2. process <URL> - å¤„ç†æŒ‡å®šè®ºæ–‡")
        print("  3. daily - è¿è¡Œæ¯æ—¥å·¥ä½œæµ")
        print("  4. stats - æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡")
        print("  5. quit - é€€å‡º")
        print("  6. report - ç”Ÿæˆå­¦ä¹ è¿›åº¦æŠ¥å‘Š")
        print("  7. feedback <index> <+|-> - å¯¹æœ€è¿‘å‘ç°çš„è®ºæ–‡è¿›è¡Œåé¦ˆ")
        print("  8. learn - æŸ¥çœ‹å­¦ä¹ çŠ¶æ€æ‘˜è¦")
        
        while not self._shutdown_event.is_set():
            try:
                # ä½¿ç”¨éé˜»å¡æ–¹å¼è¯»å–è¾“å…¥ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                command = (await asyncio.to_thread(input, "\nè¯·è¾“å…¥å‘½ä»¤: ")).strip().lower()
                
                if command == "quit" or command == "q":
                    break
                elif command == "discover":
                    papers = await self.run_discovery_cycle()
                    if papers:
                        print(f"å‘ç° {len(papers)} ç¯‡è®ºæ–‡:")
                        self._interactive_last_discovered = []
                        for i, paper in enumerate(papers[:10], 1):
                            title = getattr(getattr(paper, 'metadata', None), 'title', None) or 'Unknown Paper'
                            pid = getattr(paper, 'id', None) or f"idx-{i}"
                            self._interactive_last_discovered.append((pid, title))
                            short = pid[:8] if isinstance(pid, str) else str(pid)
                            print(f"  {i}. {title} [id:{short}]")
                elif command.startswith("process "):
                    url = command[8:].strip()
                    if url:
                        result = await self.process_paper(url)
                        if result:
                            print(f"æ–‡ç« å·²ç”Ÿæˆ: {result}")
                        else:
                            print("è®ºæ–‡å¤„ç†å¤±è´¥")
                    else:
                        print("è¯·æä¾›è®ºæ–‡URL")
                elif command == "daily":
                    await self.run_daily_workflow()
                elif command == "stats":
                    await self._show_stats()
                elif command == "report":
                    try:
                        if self.learning_loop:
                            report = await self.learning_loop.generate_progress_report()
                            print("\nğŸ§  å­¦ä¹ è¿›åº¦æŠ¥å‘Šï¼ˆå·²å†™å…¥è®°å¿†ï¼‰ï¼š")
                            print(f"  keys: {', '.join(report.keys())}")
                        else:
                            print("å­¦ä¹ å¾ªç¯æœªåˆå§‹åŒ–")
                    except Exception as _e:
                        print(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {_e}")
                elif command == "learn":
                    try:
                        if self.learning_loop:
                            summary = await self.learning_loop.get_learning_summary()
                            print("\nğŸ§  å­¦ä¹ çŠ¶æ€æ‘˜è¦ï¼š")
                            for k, v in summary.items():
                                print(f"  {k}: {v}")
                        else:
                            print("å­¦ä¹ å¾ªç¯æœªåˆå§‹åŒ–")
                    except Exception as _e:
                        print(f"è·å–å­¦ä¹ çŠ¶æ€å¤±è´¥: {_e}")
                elif command.startswith("feedback "):
                    try:
                        args = command.split()
                        if len(args) != 3 or args[2] not in ['+', '-']:
                            print("ç”¨æ³•: feedback <index> <+|->  ä¾‹å¦‚: feedback 1 +")
                        else:
                            idx = int(args[1])
                            sign = args[2]
                            if 1 <= idx <= len(self._interactive_last_discovered):
                                paper_id, title = self._interactive_last_discovered[idx - 1]
                                ok = await self.discovery_engine.provide_feedback(paper_id, feedback=(sign=='+'))
                                if ok:
                                    print(f"å·²è®°å½•åé¦ˆ: {'æ­£é¢' if sign=='+' else 'è´Ÿé¢'} -> {title}")
                                else:
                                    print("åé¦ˆå¤±è´¥")
                            else:
                                print("ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè¯·å…ˆè¿è¡Œ discover æŸ¥çœ‹åˆ—è¡¨")
                    except Exception as _e:
                        print(f"åé¦ˆå‘½ä»¤å¤±è´¥: {_e}")
                else:
                    print("æœªçŸ¥å‘½ä»¤ï¼Œè¯·é‡è¯•")
                    
            except KeyboardInterrupt:
                break
            except Exception as e:
                self.logger.error(f"äº¤äº’æ¨¡å¼é”™è¯¯: {e}", exc_info=True)
                print(f"æ‰§è¡Œé”™è¯¯: {e}")
        
        self.logger.info("é€€å‡ºäº¤äº’æ¨¡å¼")
    
    async def _show_stats(self) -> None:
        """æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats = {
                "è®°å¿†ç³»ç»Ÿ": self.memory_system.get_memory_stats(),
                "å‘ç°å¼•æ“": await self.discovery_engine.get_discovery_insights(),
                "åµŒå…¥æœåŠ¡": self.embedding_provider.get_cache_stats(),
            }
            
            print("\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯:")
            for service, service_stats in stats.items():
                print(f"\n{service}:")
                for key, value in service_stats.items():
                    print(f"  {key}: {value}")
                    
        except Exception as e:
            self.logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
            print(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
    
    async def shutdown(self) -> None:
        """ä¼˜é›…å…³é—­æ‰€æœ‰æœåŠ¡"""
        self.logger.info("å¼€å§‹å…³é—­ Deep Scholar AI")
        
        try:
            # è®¾ç½®å…³é—­äº‹ä»¶
            self._shutdown_event.set()
            
            # å…³é—­å„ä¸ªæœåŠ¡
            services = [
                ("å­¦ä¹ å¾ªç¯", self.learning_loop),
                ("åˆæˆå¼•æ“", self.synthesis_engine),
                ("åˆ†ææ ¸å¿ƒ", self.analysis_core),
                ("æ¶ˆåŒ–ç®¡é“", self.ingestion_pipeline),
                ("å‘ç°å¼•æ“", self.discovery_engine),
                ("è®°å¿†ç³»ç»Ÿ", self.memory_system),
                ("åµŒå…¥æœåŠ¡", self.embedding_provider),
                ("LLMæœåŠ¡", self.llm_provider),
            ]
            
            for service_name, service in services:
                if service and hasattr(service, 'close'):
                    try:
                        await service.close()
                        self.logger.info(f"{service_name}å·²å…³é—­")
                    except Exception as e:
                        self.logger.error(f"å…³é—­{service_name}å¤±è´¥: {e}")
            
            self.logger.info("Deep Scholar AI å·²ä¼˜é›…å…³é—­")
            print("ğŸ‘‹ Deep Scholar AI å·²å®‰å…¨å…³é—­")
            
        except Exception as e:
            print(f"å…³é—­è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Deep Scholar AI - è™šæ‹ŸAIç ”ç©¶å‘˜")
    parser.add_argument(
        "--config", 
        default="config.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)"
    )
    parser.add_argument(
        "--mode",
        choices=["daily", "interactive", "process"],
        default="interactive",
        help="è¿è¡Œæ¨¡å¼ (é»˜è®¤: interactive)"
    )
    parser.add_argument(
        "--paper-url",
        help="æŒ‡å®šè¦å¤„ç†çš„è®ºæ–‡URL (ä»…åœ¨processæ¨¡å¼ä¸‹ä½¿ç”¨)"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_path = Path(args.config)
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        print("è¯·åˆ›å»ºé…ç½®æ–‡ä»¶æˆ–ä½¿ç”¨ --config å‚æ•°æŒ‡å®šå…¶ä»–è·¯å¾„")
        sys.exit(1)
    
    # åˆ›å»ºå¹¶åˆå§‹åŒ–åº”ç”¨
    app = DeepScholarAI()
    
    try:
        await app.initialize(str(config_path))
        
        if args.mode == "daily":
            await app.run_daily_workflow()
        elif args.mode == "process":
            if not args.paper_url:
                print("âŒ processæ¨¡å¼éœ€è¦æä¾› --paper-url å‚æ•°")
                sys.exit(1)
            result = await app.process_paper(args.paper_url)
            if result:
                print(f"âœ… æ–‡ç« å·²ç”Ÿæˆ: {result}")
            else:
                print("âŒ è®ºæ–‡å¤„ç†å¤±è´¥")
                sys.exit(1)
        else:  # interactive
            await app.run_interactive_mode()
            
    except KeyboardInterrupt:
        print("\næ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·")
    except Exception as e:
        print(f"âŒ åº”ç”¨è¿è¡Œå¤±è´¥: {e}")
        traceback.print_exc()
        sys.exit(1)
    finally:
        await app.shutdown()


if __name__ == "__main__":
    # è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥ï¼ˆWindowså…¼å®¹æ€§ï¼‰
    if sys.platform == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    # è¿è¡Œä¸»å‡½æ•°
    asyncio.run(main())
