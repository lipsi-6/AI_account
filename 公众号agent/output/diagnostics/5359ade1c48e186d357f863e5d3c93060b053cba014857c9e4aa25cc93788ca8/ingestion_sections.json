[
  {
    "section_id": "section_0",
    "title": "Hierarchical Reasoning Model",
    "level": 1,
    "content_preview": "Guan Wang\\({}^{1,\\dagger}\\), Jin Li\\({}^{1}\\), Yuhao Sun\\({}^{1}\\), Xing Chen\\({}^{1}\\), Changling Liu\\({}^{1}\\),\nYue Wu\\({}^{1}\\), Meng Lu\\({}^{1,\\dagger}\\), Sen Song\\({}^{2,\\dagger}\\), Yasin Abbasi Yadkori\\({}^{1,\\dagger}\\)\n\\({}^{1}\\)Sapient Intelligence, Singapore"
  },
  {
    "section_id": "section_1",
    "title": "Abstract",
    "level": 1,
    "content_preview": "Reasoning, the process of devising and executing complex goal-oriented action sequences, remains a critical challenge in AI. Current large language models (LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from brittle task decomposition, extensive data requirements, and high latency. Inspired by the hierarchical and multi-timescale processing in the human brain, we propose the Hierarchical Reasoning Model (HRM), a novel recurrent architecture that attains significant computational depth while maintaining both training stability and efficiency. HRM executes sequential reasoning tasks in a single forward pass without explicit supervision of the intermediate process, through two interdependent recurrent modules: a high-level module responsible for slow, abstract planning"
  },
  {
    "section_id": "section_2",
    "title": "2 Hierarchical Reasoning Model",
    "level": 1,
    "content_preview": "We present the HRM, inspired by three fundamental principles of neural computation observed in the brain:\n* [leftmargin=*]\n* **Hierarchical processing:** The brain processes information across a hierarchy of cortical areas. Higher-level areas integrate information over longer timescales and form abstract representations, while lower-level areas handle more immediate, detailed sensory and motor processing [20, 22, 21].\nFigure 2: **The necessity of depth for complex reasoning. Left:** On _Sudoku-Extreme Full_, which require extensive tree-search and backtracking, increasing a Transformerâ€™s width yields no performance gain, while increasing depth is critical. **Right:** Standard architectures saturates, failing to benefit from increased depth. HRM overcomes this fundamental limitation, effect"
  },
  {
    "section_id": "section_3",
    "title": "3. Update parameters: \\[\\theta\\leftarrow\\text{OptimizerStep}(\\theta,\\nabla_{\\theta}L^{m})\\]",
    "level": 1,
    "content_preview": "The crucial aspect of this procedure is that the hidden state \\(z^{m}\\) is \"detached\" from the computation graph before being used as the input state for the next segment. Consequently, gradients from segment \\(m+1\\) do not propagate back through segment \\(m\\), effectively creating a 1-step approximation of the gradient of the recursive deep supervision process [39, 40]. This approach provides more frequent feedback to the H-module and serves as a regularization mechanism, demonstrating superior empirical performance and enhanced stability in deep equilibrium models when compared to more complex, Jacobian-based regularization techniques [39, 41]. Figure 4 shows pseudocode of deep supervision training.\n**Adaptive computational time (ACT)** The brain dynamically alternates between automatic "
  },
  {
    "section_id": "section_4",
    "title": "3.2.2 Stability of Q-learning in ACT",
    "level": 1,
    "content_preview": "The deep Q-learning that underpins our ACT mechanism is known to be prone to instability, often requiring stabilization techniques such as replay buffers and target networks [48], which are absent in our design. Our approach, however, achieves stability through the intrinsic properties of our model and training procedure. Recent theoretical work by Gallici et al. [49] shows that Q-learning can achieve convergence if network parameters are bounded, weight decay is incorporated during training, and post-normalization layers are implemented. Our model satisfies these conditions through its Post-Norm architecture that employs RMSNorm (a layer normalization variant) and the AdamW optimizer. AdamW has been shown to solve an \\(L_{\\infty}\\)-constrained optimization problem, ensuring that model par"
  },
  {
    "section_id": "section_5",
    "title": "3.2.3 Architectural details",
    "level": 1,
    "content_preview": "We employ a sequence-to-sequence architecture for HRM. Both input and output are represented as token sequences: \\(x=(x_{1},\\ldots,x_{l})\\) and \\(y=(y_{1},\\ldots,y_{l^{\\prime}})\\) respectively. The model includes an embedding layer \\(f_{I}\\) that converts discrete tokens into vector representations, and an output head \\(f_{O}(z;\\theta_{O})=\\text{softmax}(\\theta_{O}z)\\) that transforms hidden states into token probability distributions \\(\\hat{y}\\). For small-sample experiments, we replace softmax with stablemax [51] to improve generalization performance. The sequence-to-sequence loss is averaged over all tokens, \\(\\textsc{Loss}(\\hat{y},y)=\\frac{1}{l^{\\prime}}\\sum_{i=1}^{l^{\\prime}}\\log p(y_{ i})\\), where \\(p(y_{i})\\) is the probability that distribution \\(\\hat{y}_{i}\\) assigns to token \\(y_"
  },
  {
    "section_id": "section_6",
    "title": "3 Results",
    "level": 1,
    "content_preview": "This section begins by describing the ARC-AGI, Sudoku, and Maze benchmarks, followed by an overview of the baseline models and their results. Figure 6-(a,b,c) presents a visual representation of the three benchmark tasks, which are selected to evaluate various reasoning abilities in AI models."
  },
  {
    "section_id": "section_7",
    "title": "3.1.1 ARC-AGI Challenge",
    "level": 1,
    "content_preview": "The ARC-AGI benchmark evaluates general fluid intelligence through IQ-test-like puzzles that require inductive reasoning [27]. The initial version, ARC-AGI-1, presents challenges as input-output grid pairs that force AI systems to extract and generalize abstract rules from just a few examples. Each task provides a few input-output example pairs (usually 2-3) and a test input. An AI model has two attempts to produce the correct output grid. Although some believe that mastering ARC-AGI would signal true artificial general intelligence, its primary purpose is to expose the current roadblocks in AGI progress. In fact, both conventional deep learning methods and CoT techniques have faced significant challenges with ARC-AGI-1, primarily because it requires the ability to generalize to entirely n"
  },
  {
    "section_id": "section_8",
    "title": "Visualization of intermediate timesteps",
    "level": 1,
    "content_preview": "Although HRM demonstrates strong performance on complex reasoning tasks, it raises an intriguing question: what underlying reasoning algorithms does the HRM neural network actually implement? Addressing this question is important for enhancing model interpretability and developing a deeper understanding of the HRM solution space.\nWhile a definitive answer lies beyond our current scope, we begin our investigation by analyzing state trajectories and their corresponding solution evolution. More specifically, at each timestep \\(i\\) and given the low-level and high-level state pair (\\(z^{i}_{L}\\) and \\(z^{i}_{H}\\)) we perform a preliminary forward pass through the H-module to obtain \\(\\bar{z}^{i}=f_{H}(z^{i}_{H},z^{i}_{L};\\theta_{H})\\) and its corresponding decoded prediction \\(\\bar{y}^{i}=f_{O"
  },
  {
    "section_id": "section_9",
    "title": "4 Brain Correspondence",
    "level": 1,
    "content_preview": "A key principle from systems neuroscience is that a brain region's functional repertoire--its ability to handle diverse and complex tasks--is closely linked to the dimensionality of its neural representations [75, 76]. Higher-order cortical areas, responsible for complex reasoning and decision-making, must handle a wide variety of tasks, demanding more flexible and context-dependent processing [77]. In dynamical systems, this flexibility is often realized through higher-dimensional state-space trajectories, which allow for a richer repertoire of potential computations [78]. This principle gives rise to an observable _dimensionality hierarchy_, where a region's position in the processing hierarchy correlates with its _effective dimensionality_. To quantify this phenomenon, we can examine th"
  },
  {
    "section_id": "section_10",
    "title": "5.0.1 Reasoning and algorithm learning",
    "level": 1,
    "content_preview": "Given the central role of reasoning problems and their close relation to algorithms, researchers have long explored neural architectures that enable algorithm learning from training instances. This line of work includes Neural Turing Machines (NTM)[83], the Differentiable Neural Computer (DNC)[84], and Neural GPUs[85]-all of which construct iterative neural architectures that mimic computational hardware for algorithm execution, and are trained to learn algorithms from data. Another notable work in this area is Recurrent Relational Networks (RRN)[62], which executes algorithms on graph representations through graph neural networks.\nRecent studies have integrated algorithm learning approaches with Transformer-based architectures. Universal Transformers extend the standard Transformer model "
  },
  {
    "section_id": "section_11",
    "title": "5.0.2 Brain-inspired reasoning architectures",
    "level": 1,
    "content_preview": "Developing a model with the reasoning power of the brain has long been a goal in brain-inspired computing. Spaun[90] is one notable example, which uses spiking neural networks to create distinct modules corresponding to brain regions like the visual cortex and prefrontal cortex. This design enables an architecture to perform a range of cognitive tasks, from memory recall to simple reasoning puzzles. However, its reasoning relies on hand-designed algorithms, which may limit its ability to learn new tasks. Another significant model is the Tolman-Eichenbaum Machine (TEM)[91], which is inspired by the hippocampal-entorhinal system's role in spatial and relational memory tasks. TEM proposes that medial entorhinal cells create a basis for structural knowledge, while hippocampal cells link this b"
  },
  {
    "section_id": "section_12",
    "title": "6 Discussions",
    "level": 1,
    "content_preview": "**Turing-completeness of HRM**: Like earlier neural reasoning algorithms including the Universal Transformer [95], HRM is computationally universal when given sufficient memory and time constraints. In other words, it falls into the category of models that can simulate any Turing machine, overcoming the computational limitations of standard Transformers discussed previously in the introduction. Given that earlier neural algorithm reasoners were trained as recurrent neural networks, they suffer from premature convergence and memory intensive BPTT. Therefore, in practice, their effective computational depth remains limited, though still deeper than that of a standard Transformer. By resolving these two challenges and being equipped with adaptive computation, HRM could be trained on long reas"
  },
  {
    "section_id": "section_13",
    "title": "7 Conclusion",
    "level": 1,
    "content_preview": "This work introduces the Hierarchical Reasoning Model, a brain-inspired architecture that leverages hierarchical structure and multi-timescale processing to achieve substantial computational depth without sacrificing training stability or efficiency. With only 27M parameters and training on just 1000 examples, HRM effectively solves challenging reasoning problems such as ARC, Sudoku, and complex maze navigation-tasks that typically pose significant difficulties for contemporary LLM and chain-of-thought models.\nAlthough the brain relies heavily on hierarchical structures to enable most cognitive processes, these concepts have largely remained confined to academic literature rather than being translated into practical applications. The prevailing AI approach continues to favor non-hierarchic"
  },
  {
    "section_id": "section_14",
    "title": "References",
    "level": 1,
    "content_preview": "* [1] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. _Deep Learning_. MIT Press, 2016. http://www.deeplearningbook.org.\n* [2] Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. _2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 770-778, 2015.\n* [3] Lena Strobl. Average-hard attention transformers are constant-depth uniform threshold circuits, 2023.\n* [4] Tom Bylander. Complexity results for planning. In _Proceedings of the 12th International Joint Conference on Artificial Intelligence - Volume 1_, IJCAI'91, page 274-279, San Francisco, CA, USA, 1991. Morgan Kaufmann Publishers Inc. ISBN 1558601600.\n* [5] William Merrill and Ashish Sabharwal. A logic for expressing log-precision transformers. In _Neural Informati"
  }
]