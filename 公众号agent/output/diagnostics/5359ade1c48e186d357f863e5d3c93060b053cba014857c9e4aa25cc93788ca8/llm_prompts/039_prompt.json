{
  "timestamp": "2025-08-19T08:26:43.999040+00:00",
  "model": "deepseek-chat",
  "temperature": 0.2,
  "max_tokens": 48,
  "system_prompt": null,
  "use_insight_model": false,
  "messages": [
    {
      "role": "user",
      "content": "你是一位学术编辑。请基于如下论文上下文与片段内容，生成一个高度概括的中文主题短语（8-16字），不含标点，不要解释：\n论文标题: 测试论文\n研究领域: Artificial Intelligence\n关键贡献: Proposal of HRM, a hierarchical recurrent model for deep reasoning tasks, Demonstration of HRM's ability to solve complex tasks with minimal training data (1000 examples), Elimination of dependency on pre-training or CoT techniques\n片段:\n_Deep Learning_. deeplearningbook. Deep residual learning for image recognition. _2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 770-778, 2015. Complexity results for planning. In _Proceedings of the 12th International Joint Conference on Artificial Intelligence - Volume 1_, IJCAI'91, page 274-279, San Francisco, CA, USA, 1991. In _Neural Information Processing Systems_, 2023. _Transactions on Machine Learning Research_, 2025. Beyond a*: Better planning with transformers via search dynamics bootstrapping. In _First Conference on Language Modeling_, 2024. _Transactions of the Association for Computational Linguistics_, 11:531-545, 2023. Chain-of-thought prompting elicits reasoning in large language models, 2022. Premise order matters in reasoning with large language models. Preemptive answer \"attacks\" on chain-of-thought reasoning. In _Annual Meeting of the Association for Computational Linguistics_, 2024. limits of llm scaling based on human-generated data. Reasoning beyond language: A comprehensive survey on latent chain-of-thought reasoning, 2025. Training large language models to reason in a continuous latent space. Language is primarily a tool fo"
    }
  ],
  "additional_params": {}
}